import os
import google.generativeai as genai
from supabase import create_client, Client
from langchain_community.document_loaders import PyPDFLoader
# --- ESTA ES LA L√çNEA CORREGIDA (con guion bajo) ---
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# Configurar clientes
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
genai.configure(api_key=GOOGLE_API_KEY)

def run_ingest():
    print("üöÄ Iniciando proceso de ingesti√≥n...")

    # A. LIMPIEZA DE DATOS ANTIGUOS
    print("üóëÔ∏è  Borrando datos antiguos...")
    try:
        supabase.table("documents").delete().neq("id", 0).execute()
    except Exception as e:
        print(f"‚ö†Ô∏è Nota: No se pudo limpiar la tabla (quiz√°s estaba vac√≠a): {e}")

    # B. CARGAR EL PDF
    pdf_path = "faq.pdf" 
    if not os.path.exists(pdf_path):
        print(f"‚ùå Error: No encuentro el archivo '{pdf_path}'")
        return

    try:
        loader = PyPDFLoader(pdf_path)
        docs = loader.load()
        print(f"üìÑ PDF cargado. Total de p√°ginas: {len(docs)}")
    except Exception as e:
        print(f"‚ùå Error al leer el PDF: {e}")
        return

    # C. DIVIDIR EL TEXTO
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    chunks = text_splitter.split_documents(docs)
    print(f"üß© Texto dividido en {len(chunks)} fragmentos.")

    # D. GENERAR EMBEDDINGS Y SUBIR
    print("üß† Generando vectores y subiendo a Supabase... (Ignora las advertencias de Google)")
    
    for i, chunk in enumerate(chunks):
        content = chunk.page_content
        
        try:
            # Generar embedding
            response = genai.embed_content(
                model="models/text-embedding-004",
                content=content,
                task_type="retrieval_document"
            )
            embedding = response['embedding']

            # Preparar y subir
            data = {
                "content": content,
                "metadata": chunk.metadata,
                "embedding": embedding
            }
            supabase.table("documents").insert(data).execute()
            
            if i % 5 == 0:
                print(f"   ... Procesado fragmento {i+1}/{len(chunks)}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Error en el fragmento {i}: {e}")

    print("‚úÖ ¬°Listo! La base de datos de UniBot ha sido actualizada.")

if __name__ == "__main__":
    run_ingest()