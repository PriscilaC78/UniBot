import os
from fastapi.middleware.cors import CORSMiddleware
import google.generativeai as genai
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from supabase import create_client, Client
from dotenv import load_dotenv

# 1. Configuraci√≥n inicial
load_dotenv()
app = FastAPI()

# Configuraci√≥n de permisos (CORS)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 2. Conexi√≥n a Servicios
supabase_url = os.getenv("SUPABASE_URL")
supabase_key = os.getenv("SUPABASE_KEY")
google_api_key = os.getenv("GOOGLE_API_KEY")

if not supabase_url or not google_api_key:
    raise ValueError("‚ùå Error: Faltan las variables de entorno.")

# Inicializamos clientes
try:
    supabase: Client = create_client(supabase_url, supabase_key)
    genai.configure(api_key=google_api_key)
except Exception as e:
    print(f"‚ùå Error al conectar servicios: {e}")

# Modelo de datos
class UserQuery(BaseModel):
    pregunta: str
    session_id: str = "anonimo"

# 3. Funci√≥n para buscar informaci√≥n
def buscar_contexto(pregunta_usuario: str):
    try:
        # A. Embedding
        # NOTA: Para embeddings, 'models/' suele ser necesario, pero para chat no.
        result = genai.embed_content(
            model="models/text-embedding-004", 
            content=pregunta_usuario,
            task_type="retrieval_query"
        )
        query_vector = result['embedding']

        # B. B√∫squeda en Supabase
        response = supabase.rpc("match_documents", {
            "query_embedding": query_vector,
            "match_threshold": 0.4, # Lo baj√© un poquito para que encuentre m√°s cosas
            "match_count": 3
        }).execute()
        
        # C. Unir texto
        contexto = "\n\n".join([item['content'] for item in response.data])
        return contexto
        
    except Exception as e:
        print(f"‚ö†Ô∏è Advertencia buscando contexto: {e}")
        return ""

# 4. El Cerebro del Chat
@app.post("/chat")
async def chat_endpoint(query: UserQuery):
    print(f"üì© Pregunta recibida: {query.pregunta}")

    # --- DETECTOR DE SALUDOS ---
    saludos = ["hola", "buen dia", "buen d√≠a", "buenas", "que tal", "hello", "hi"]
    mensaje_usuario = query.pregunta.lower().strip()
    
    if any(s in mensaje_usuario for s in saludos) and len(mensaje_usuario) < 20:
        return {"respuesta": "¬°Hola! üëã Soy UniBot, el asistente virtual de Alumnado UNCAUS. ¬øEn qu√© tr√°mite, fecha o requisito puedo ayudarte hoy?"}
    # ---------------------------

    # 1. Buscamos informaci√≥n
    contexto = buscar_contexto(query.pregunta)
    
    # 2. Instrucciones
    prompt = f"""
    Eres UniBot, el asistente virtual de la UNCAUS.
    Responde la pregunta del usuario bas√°ndote EXCLUSIVAMENTE en el siguiente contexto.

    CONTEXTO RECUPERADO:
    "{contexto}"

    ---
    INSTRUCCIONES:
    1. Usa la informaci√≥n del CONTEXTO para responder.
    2. Si la respuesta NO est√° en el contexto, di textualmente: "Lo siento, no tengo informaci√≥n sobre ese tema espec√≠fico en mi base de conocimientos de Alumnado."
    3. S√© amable, breve y usa emojis.
    """ 

    # 3. Generamos la respuesta con Gemini
    try:
        # --- AQU√ç ESTABA EL ERROR ---
        # Cambiamos 'models/gemini-1.5-flash' por 'gemini-1.5-flash'
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        response = model.generate_content(prompt)
        respuesta_final = response.text
    except Exception as e:
        # Si falla Flash, intentamos con Pro como respaldo
        try:
            print(f"‚ö†Ô∏è Fall√≥ Flash, intentando con Pro... Error: {e}")
            model_backup = genai.GenerativeModel('gemini-pro')
            response = model_backup.generate_content(prompt)
            respuesta_final = response.text
        except Exception as e2:
            respuesta_final = "Lo siento, hubo un error t√©cnico al conectar con la IA."
            print(f"‚ùå Error Gemini Cr√≠tico: {e2}")

    # 4. Guardamos log
    try:
        supabase.table("chat_logs").insert({
            "session_id": query.session_id,
            "user_input": query.pregunta,
            "bot_response": respuesta_final
        }).execute()
    except Exception as e:
        print(f"‚ö†Ô∏è No se pudo guardar el log: {e}")

    return {"respuesta": respuesta_final}

@app.get("/")
def home():
    return {"UniBot ACTUALIZADO v2 üöÄ"}
